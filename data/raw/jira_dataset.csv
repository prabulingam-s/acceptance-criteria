Description|Acceptance Criteria
"As a data engineer, I want to add a new column to an existing Hive table so that I can store additional data."|"Scenario: Add New Column to Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to add a new column \n Then: The new column should be added to the table schema"
"As a data engineer, I want to rename a column in a Hive table so that the column name is more descriptive."|"Scenario: Rename Column in Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to rename the column \n Then: The column name should be updated in the table schema"
"As a data engineer, I want to change the data type of a column in a Hive table so that it can store different types of data."|"Scenario: Change Column Data Type in Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to change the column data type \n Then: The column data type should be updated in the table schema"
"As a data engineer, I want to drop a column from a Hive table so that I can remove unnecessary data."|"Scenario: Drop Column from Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to drop the column \n Then: The column should be removed from the table schema"
"As a data engineer, I want to partition a Hive table so that I can improve query performance."|"Scenario: Partition Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to add partitions \n Then: The table should be partitioned as specified"
"As a data engineer, I want to add a new Hive table so that I can store data for a new dataset."|"Scenario: Create New Hive Table \n Given: The dataset is available \n When: I execute a CREATE TABLE command \n Then: The new Hive table should be created with the specified schema"
"As a data engineer, I want to update the metadata of a Hive table so that it reflects the latest changes."|"Scenario: Update Hive Table Metadata \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to update the metadata \n Then: The table metadata should be updated"
"As a data engineer, I want to backfill data into a Hive table so that historical data is available for analysis."|"Scenario: Backfill Data into Hive Table \n Given: The historical data is available \n When: I execute an INSERT command to backfill the data \n Then: The historical data should be added to the Hive table"
"As a data engineer, I want to merge two Hive tables so that I can combine data from different sources."|"Scenario: Merge Two Hive Tables \n Given: Two Hive tables exist \n When: I execute a MERGE command \n Then: The data from both tables should be combined into one table"
"As a data engineer, I want to optimize a Hive table so that queries run faster."|"Scenario: Optimize Hive Table \n Given: The Hive table exists \n When: I execute an OPTIMIZE command \n Then: The table should be optimized for better query performance"
"As a data engineer, I want to compress data in a Hive table so that it occupies less storage."|"Scenario: Compress Data in Hive Table \n Given: The Hive table exists \n When: I execute a command to enable compression \n Then: The data in the table should be compressed"
"As a data engineer, I want to enable ACID transactions on a Hive table so that I can perform CRUD operations."|"Scenario: Enable ACID Transactions on Hive Table \n Given: The Hive table exists \n When: I execute a command to enable ACID transactions \n Then: The table should support ACID transactions"
"As a data engineer, I want to update rows in a Hive table so that the data remains accurate."|"Scenario: Update Rows in Hive Table \n Given: The Hive table exists \n When: I execute an UPDATE command \n Then: The specified rows should be updated"
"As a data engineer, I want to delete rows from a Hive table so that outdated data is removed."|"Scenario: Delete Rows from Hive Table \n Given: The Hive table exists \n When: I execute a DELETE command \n Then: The specified rows should be deleted"
"As a data engineer, I want to insert new rows into a Hive table so that the data is up-to-date."|"Scenario: Insert Rows into Hive Table \n Given: The Hive table exists \n When: I execute an INSERT command \n Then: The new rows should be added to the table"
"As a data engineer, I want to create a view on a Hive table so that I can simplify complex queries."|"Scenario: Create View on Hive Table \n Given: The Hive table exists \n When: I execute a CREATE VIEW command \n Then: The view should be created and accessible"
"As a data engineer, I want to drop a Hive table so that I can remove unused data."|"Scenario: Drop Hive Table \n Given: The Hive table exists \n When: I execute a DROP TABLE command \n Then: The table should be removed from the database"
"As a data engineer, I want to add a comment to a Hive table so that other users understand its purpose."|"Scenario: Add Comment to Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to add a comment \n Then: The comment should be added to the table metadata"
"As a data engineer, I want to add a comment to a column in a Hive table so that other users understand its purpose."|"Scenario: Add Comment to Column in Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to add a comment to the column \n Then: The comment should be added to the column metadata"
"As a data engineer, I want to create an external Hive table so that I can manage data stored outside Hive."|"Scenario: Create External Hive Table \n Given: The data is stored in an external location \n When: I execute a CREATE EXTERNAL TABLE command \n Then: The external table should be created and linked to the data"
"As a data engineer, I want to create a managed Hive table so that I can store data within Hive."|"Scenario: Create Managed Hive Table \n Given: The data is available \n When: I execute a CREATE TABLE command \n Then: The managed table should be created within Hive"
"As a data engineer, I want to change the file format of a Hive table so that it supports different storage formats."|"Scenario: Change File Format of Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to change the file format \n Then: The table should use the new file format"
"As a data engineer, I want to add a new partition to a Hive table so that I can store new data."|"Scenario: Add New Partition to Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to add a partition \n Then: The new partition should be added to the table"
"As a data engineer, I want to drop a partition from a Hive table so that I can remove outdated data."|"Scenario: Drop Partition from Hive Table \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to drop a partition \n Then: The partition should be removed from the table"
"As a data engineer, I want to update the location of a Hive table so that it points to a new data source."|"Scenario: Update Hive Table Location \n Given: The Hive table exists \n When: I execute an ALTER TABLE command to update the location \n Then: The table should point to the new data source"
"As a data engineer, I want to create a bucketed Hive table so that I can improve query performance."|"Scenario: Create Bucketed Hive Table \n Given: The data is available \n When: I execute a CREATE TABLE command with bucketing \n Then: The table should be created with the specified number of buckets"
"As a data engineer, I want to enable dynamic partitioning in a Hive table so that partitions are created automatically."|"Scenario: Enable Dynamic Partitioning in Hive Table \n Given: The Hive table exists \n When: I execute a command to enable dynamic partitioning \n Then: The table should automatically create partitions based on the data"
"As a data engineer, I want to disable dynamic partitioning in a Hive table so that partitions are created manually."|"Scenario: Disable Dynamic Partitioning in Hive Table \n Given: The Hive table exists \n When: I execute a command to disable dynamic partitioning \n Then: The table should require manual partition creation"
"As a data engineer, I want to create a Hive table with a custom SerDe so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom SerDe \n Given: The custom SerDe is available \n When: I execute a CREATE TABLE command with the custom SerDe \n Then: The table should be created and use the custom SerDe"
"As a data engineer, I want to create a Hive table with a custom input format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Input Format \n Given: The custom input format is available \n When: I execute a CREATE TABLE command with the custom input format \n Then: The table should be created and use the custom input format"
"As a data engineer, I want to create a Hive table with a custom output format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Output Format \n Given: The custom output format is available \n When: I execute a CREATE TABLE command with the custom output format \n Then: The table should be created and use the custom output format"
"As a data engineer, I want to create a Hive table with a custom storage handler so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Storage Handler \n Given: The custom storage handler is available \n When: I execute a CREATE TABLE command with the custom storage handler \n Then: The table should be created and use the custom storage handler"
"As a data engineer, I want to create a Hive table with a custom file format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom File Format \n Given: The custom file format is available \n When: I execute a CREATE TABLE command with the custom file format \n Then: The table should be created and use the custom file format"
"As a data engineer, I want to create a Hive table with a custom compression codec so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Compression Codec \n Given: The custom compression codec is available \n When: I execute a CREATE TABLE command with the custom compression codec \n Then: The table should be created and use the custom compression codec"
"As a data engineer, I want to create a Hive table with a custom row format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Row Format \n Given: The custom row format is available \n When: I execute a CREATE TABLE command with the custom row format \n Then: The table should be created and use the custom row format"
"As a data engineer, I want to create a Hive table with a custom column delimiter so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Column Delimiter \n Given: The custom column delimiter is available \n When: I execute a CREATE TABLE command with the custom column delimiter \n Then: The table should be created and use the custom column delimiter"
"As a data engineer, I want to create a Hive table with a custom line delimiter so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Line Delimiter \n Given: The custom line delimiter is available \n When: I execute a CREATE TABLE command with the custom line delimiter \n Then: The table should be created and use the custom line delimiter"
"As a data engineer, I want to create a Hive table with a custom escape character so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Escape Character \n Given: The custom escape character is available \n When: I execute a CREATE TABLE command with the custom escape character \n Then: The table should be created and use the custom escape character"
"As a data engineer, I want to create a Hive table with a custom null format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Null Format \n Given: The custom null format is available \n When: I execute a CREATE TABLE command with the custom null format \n Then: The table should be created and use the custom null format"
"As a data engineer, I want to create a Hive table with a custom timestamp format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Timestamp Format \n Given: The custom timestamp format is available \n When: I execute a CREATE TABLE command with the custom timestamp format \n Then: The table should be created and use the custom timestamp format"
"As a data engineer, I want to create a Hive table with a custom date format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Date Format \n Given: The custom date format is available \n When: I execute a CREATE TABLE command with the custom date format \n Then: The table should be created and use the custom date format"
"As a data engineer, I want to create a Hive table with a custom decimal format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Decimal Format \n Given: The custom decimal format is available \n When: I execute a CREATE TABLE command with the custom decimal format \n Then: The table should be created and use the custom decimal format"
"As a data engineer, I want to create a Hive table with a custom boolean format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Boolean Format \n Given: The custom boolean format is available \n When: I execute a CREATE TABLE command with the custom boolean format \n Then: The table should be created and use the custom boolean format"
"As a data engineer, I want to create a Hive table with a custom binary format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Binary Format \n Given: The custom binary format is available \n When: I execute a CREATE TABLE command with the custom binary format \n Then: The table should be created and use the custom binary format"
"As a data engineer, I want to create a Hive table with a custom array format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Array Format \n Given: The custom array format is available \n When: I execute a CREATE TABLE command with the custom array format \n Then: The table should be created and use the custom array format"
"As a data engineer, I want to create a Hive table with a custom map format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Map Format \n Given: The custom map format is available \n When: I execute a CREATE TABLE command with the custom map format \n Then: The table should be created and use the custom map format"
"As a data engineer, I want to create a Hive table with a custom struct format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Struct Format \n Given: The custom struct format is available \n When: I execute a CREATE TABLE command with the custom struct format \n Then: The table should be created and use the custom struct format"
"As a data engineer, I want to create a Hive table with a custom union format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Union Format \n Given: The custom union format is available \n When: I execute a CREATE TABLE command with the custom union format \n Then: The table should be created and use the custom union format"
"As a data engineer, I want to create a Hive table with a custom enum format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Enum Format \n Given: The custom enum format is available \n When: I execute a CREATE TABLE command with the custom enum format \n Then: The table should be created and use the custom enum format"
"As a data engineer, I want to create a Hive table with a custom set format so that I can handle custom data formats."|"Scenario: Create Hive Table with Custom Set Format \n Given: The custom set format is available \n When: I execute a CREATE TABLE command with the custom set format \n Then: The table should be created and use the custom set format"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"
"As a developer, I need to create a partitioned table to match the user schema and load data daily, scheduling the job in Autosys."|"Scenario: Create the partitioned table to load the source data daily and schedule the job in Autosys \n Given: Source data schema is available, and the table DDL is attached in Jira \n When: We create the table and load script and schedule it in Autosys on a daily basis \n Then: The job should fetch the data and load it on a daily basis"
"As a developer, I want to implement bucketing in Hive tables to optimize query performance and reduce shuffle operations."|"Scenario: Optimize Hive queries by implementing bucketing \n Given: The Hive table schema is defined, and bucket keys are identified \n When: We create a table with bucketing and load data accordingly \n Then: Query performance should improve by reducing shuffle operations"
"As a data engineer, I need to enable dynamic partitioning in Hive so that new partitions are created automatically when new data arrives."|"Scenario: Enable dynamic partitioning to handle incremental data \n Given: The Hive table supports partitioning, and incoming data contains partition keys \n When: We configure hive.exec.dynamic.partition and hive.exec.dynamic.partition.mode to allow dynamic partitions \n Then: The system should create partitions dynamically as new data arrives"
"As a data engineer, I want to create an external Hive table to read data stored in S3 without moving it."|"Scenario: Set up an external Hive table linked to S3 \n Given: The S3 bucket and data files are accessible \n When: We create an external Hive table with the correct schema \n Then: The table should query data directly from S3 without moving it into HDFS"
"As a developer, I need to enable ACID transactions in Hive to support row-level updates and deletes."|"Scenario: Enable ACID transactions for a managed Hive table \n Given: The Hive table is a managed table stored in ORC format \n When: We configure hive.txn.manager and enable hive.compactor.initiator.on \n Then: The table should support row-level updates, inserts, and deletes"